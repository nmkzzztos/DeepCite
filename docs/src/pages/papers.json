[
    {
        "id": "understanding-the-planning-of-llm-agents-a-survey",
        "title": "Understanding the planning of LLM agents: A survey",
        "authors": "Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, Enhong Chen",
        "year": 2024,
        "abstract": "As Large Language Models (LLMs) have shown significant intelligence, the\nprogress to leverage LLMs as planning modules of autonomous agents has\nattracted more attention. This survey provides the first systematic view of\nLLM-based agents planning, covering recent works aiming to improve planning\nability. We provide a taxonomy of existing works on LLM-Agent planning, which\ncan be categorized into Task Decomposition, Plan Selection, External Module,\nReflection and Memory. Comprehensive analyses are conducted for each direction,\nand further challenges for the field of research are discussed.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2402.02716v1",
        "arxiv": "2402.02716v1",
        "pdf": "http://arxiv.org/pdf/2402.02716v1",
        "citations": 304
    },
    {
        "id": "critic-large-language-models-can-self-correct-with-tool-interactive-critiquing",
        "title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive\n  Critiquing",
        "authors": "Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, Weizhu Chen",
        "year": 2023,
        "abstract": "Recent developments in large language models (LLMs) have been impressive.\nHowever, these models sometimes show inconsistencies and problematic behavior,\nsuch as hallucinating facts, generating flawed code, or creating offensive and\ntoxic content. Unlike these models, humans typically utilize external tools to\ncross-check and refine their initial content, like using a search engine for\nfact-checking, or a code interpreter for debugging. Inspired by this\nobservation, we introduce a framework called CRITIC that allows LLMs, which are\nessentially \"black boxes\" to validate and progressively amend their own outputs\nin a manner similar to human interaction with tools. More specifically,\nstarting with an initial output, CRITIC interacts with appropriate tools to\nevaluate certain aspects of the text, and then revises the output based on the\nfeedback obtained during this validation process. Comprehensive evaluations\ninvolving free-form question answering, mathematical program synthesis, and\ntoxicity reduction demonstrate that CRITIC consistently enhances the\nperformance of LLMs. Meanwhile, our research highlights the crucial importance\nof external feedback in promoting the ongoing self-improvement of LLMs.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2305.11738v4",
        "arxiv": "2305.11738v4",
        "pdf": "http://arxiv.org/pdf/2305.11738v4",
        "citations": 485
    },
    {
        "id": "reflexion-language-agents-with-verbal-reinforcement-learning",
        "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
        "authors": "Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao",
        "year": 2023,
        "abstract": "Large language models (LLMs) have been increasingly used to interact with\nexternal environments (e.g., games, compilers, APIs) as goal-driven agents.\nHowever, it remains challenging for these language agents to quickly and\nefficiently learn from trial-and-error as traditional reinforcement learning\nmethods require extensive training samples and expensive model fine-tuning. We\npropose Reflexion, a novel framework to reinforce language agents not by\nupdating weights, but instead through linguistic feedback. Concretely,\nReflexion agents verbally reflect on task feedback signals, then maintain their\nown reflective text in an episodic memory buffer to induce better\ndecision-making in subsequent trials. Reflexion is flexible enough to\nincorporate various types (scalar values or free-form language) and sources\n(external or internally simulated) of feedback signals, and obtains significant\nimprovements over a baseline agent across diverse tasks (sequential\ndecision-making, coding, language reasoning). For example, Reflexion achieves a\n91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous\nstate-of-the-art GPT-4 that achieves 80%. We also conduct ablation and analysis\nstudies using different feedback signals, feedback incorporation methods, and\nagent types, and provide insights into how they affect performance.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2303.11366v4",
        "arxiv": "2303.11366v4",
        "pdf": "http://arxiv.org/pdf/2303.11366v4",
        "citations": 2431
    },
    {
        "id": "self-refine-iterative-refinement-with-self-feedback",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback",
        "authors": "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, Peter Clark",
        "year": 2023,
        "abstract": "Like humans, large language models (LLMs) do not always generate the best\noutput on their first try. Motivated by how humans refine their written text,\nwe introduce Self-Refine, an approach for improving initial outputs from LLMs\nthrough iterative feedback and refinement. The main idea is to generate an\ninitial output using an LLMs; then, the same LLMs provides feedback for its\noutput and uses it to refine itself, iteratively. Self-Refine does not require\nany supervised training data, additional training, or reinforcement learning,\nand instead uses a single LLM as the generator, refiner, and feedback provider.\nWe evaluate Self-Refine across 7 diverse tasks, ranging from dialog response\ngeneration to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT,\nand GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine\nare preferred by humans and automatic metrics over those generated with the\nsame LLM using conventional one-step generation, improving by ~20% absolute on\naverage in task performance. Our work demonstrates that even state-of-the-art\nLLMs like GPT-4 can be further improved at test time using our simple,\nstandalone approach.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2303.17651v2",
        "arxiv": "2303.17651v2",
        "pdf": "http://arxiv.org/pdf/2303.17651v2",
        "citations": 2444
    },
    {
        "id": "enhancing-retrieval-augmented-large-language-models-with-iterative-retrieval-generation-synergy",
        "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative\n  Retrieval-Generation Synergy",
        "authors": "Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, Weizhu Chen",
        "year": 2023,
        "abstract": "Large language models are powerful text processors and reasoners, but are\nstill subject to limitations including outdated knowledge and hallucinations,\nwhich necessitates connecting them to the world. Retrieval-augmented large\nlanguage models have raised extensive attention for grounding model generation\non external knowledge. However, retrievers struggle to capture relevance,\nespecially for queries with complex information needs. Recent work has proposed\nto improve relevance modeling by having large language models actively involved\nin retrieval, i.e., to improve retrieval with generation. In this paper, we\nshow that strong performance can be achieved by a method we call Iter-RetGen,\nwhich synergizes retrieval and generation in an iterative manner. A model\noutput shows what might be needed to finish a task, and thus provides an\ninformative context for retrieving more relevant knowledge which in turn helps\ngenerate a better output in the next iteration. Compared with recent work which\ninterleaves retrieval with generation when producing an output, Iter-RetGen\nprocesses all retrieved knowledge as a whole and largely preserves the\nflexibility in generation without structural constraints. We evaluate\nIter-RetGen on multi-hop question answering, fact verification, and commonsense\nreasoning, and show that it can flexibly leverage parametric knowledge and\nnon-parametric knowledge, and is superior to or competitive with\nstate-of-the-art retrieval-augmented baselines while causing fewer overheads of\nretrieval and generation. We can further improve performance via\ngeneration-augmented retrieval adaptation.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2305.15294v2",
        "arxiv": "2305.15294v2",
        "pdf": "http://arxiv.org/pdf/2305.15294v2",
        "citations": 381
    },
    {
        "id": "demonstrate-search-predict-composing-retrieval-and-language-models-for-knowledge-intensive-nlp",
        "title": "Demonstrate-Search-Predict: Composing retrieval and language models for\n  knowledge-intensive NLP",
        "authors": "Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, Matei Zaharia",
        "year": 2022,
        "abstract": "Retrieval-augmented in-context learning has emerged as a powerful approach\nfor addressing knowledge-intensive tasks using frozen language models (LM) and\nretrieval models (RM). Existing work has combined these in simple\n\"retrieve-then-read\" pipelines in which the RM retrieves passages that are\ninserted into the LM prompt. To begin to fully realize the potential of frozen\nLMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that\nrelies on passing natural language texts in sophisticated pipelines between an\nLM and an RM. DSP can express high-level programs that bootstrap pipeline-aware\ndemonstrations, search for relevant passages, and generate grounded\npredictions, systematically breaking down problems into small transformations\nthat the LM and RM can handle more reliably. We have written novel DSP programs\nfor answering questions in open-domain, multi-hop, and conversational settings,\nestablishing in early evaluations new state-of-the-art in-context learning\nresults and delivering 37-120%, 8-39%, and 80-290% relative gains against the\nvanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a\ncontemporaneous self-ask pipeline, respectively. We release DSP at\nhttps://github.com/stanfordnlp/dsp",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2212.14024v2",
        "arxiv": "2212.14024v2",
        "pdf": "http://arxiv.org/pdf/2212.14024v2",
        "citations": 325
    },
    {
        "id": "vision-language-models-for-vision-tasks-a-survey",
        "title": "Vision-Language Models for Vision Tasks: A Survey",
        "authors": "Jingyi Zhang, Jiaxing Huang, Sheng Jin, Shijian Lu",
        "year": 2023,
        "abstract": "Most visual recognition studies rely heavily on crowd-labelled data in deep\nneural networks (DNNs) training, and they usually train a DNN for each single\nvisual recognition task, leading to a laborious and time-consuming visual\nrecognition paradigm. To address the two challenges, Vision-Language Models\n(VLMs) have been intensively investigated recently, which learns rich\nvision-language correlation from web-scale image-text pairs that are almost\ninfinitely available on the Internet and enables zero-shot predictions on\nvarious visual recognition tasks with a single VLM. This paper provides a\nsystematic review of visual language models for various visual recognition\ntasks, including: (1) the background that introduces the development of visual\nrecognition paradigms; (2) the foundations of VLM that summarize the\nwidely-adopted network architectures, pre-training objectives, and downstream\ntasks; (3) the widely-adopted datasets in VLM pre-training and evaluations; (4)\nthe review and categorization of existing VLM pre-training methods, VLM\ntransfer learning methods, and VLM knowledge distillation methods; (5) the\nbenchmarking, analysis and discussion of the reviewed methods; (6) several\nresearch challenges and potential research directions that could be pursued in\nthe future VLM studies for visual recognition. A project associated with this\nsurvey has been created at https://github.com/jingyi0000/VLM_survey.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2304.00685v2",
        "arxiv": "2304.00685v2",
        "pdf": "http://arxiv.org/pdf/2304.00685v2",
        "citations": 1035
    },
    {
        "id": "hallucination-is-inevitable-an-innate-limitation-of-large-language-models",
        "title": "Hallucination is Inevitable: An Innate Limitation of Large Language\n  Models",
        "authors": "Ziwei Xu, Sanjay Jain, Mohan Kankanhalli",
        "year": 2023,
        "abstract": "Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all the computable functions and will\ntherefore inevitably hallucinate if used as general problem solvers. Since the\nformal world is a part of the real world which is much more complicated,\nhallucinations are also inevitable for real world LLMs. Furthermore, for real\nworld LLMs constrained by provable time complexity, we describe the\nhallucination-prone tasks and empirically validate our claims. Finally, using\nthe formal world framework, we discuss the possible mechanisms and efficacies\nof existing hallucination mitigators as well as the practical implications on\nthe safe deployment of LLMs.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2401.11817v2",
        "arxiv": "2401.11817v2",
        "pdf": "http://arxiv.org/pdf/2401.11817v2",
        "citations": 2913
    },
    {
        "id": "a-survey-on-hallucination-in-large-language-models-principles-taxonomy-challenges-and-open-questions",
        "title": "A Survey on Hallucination in Large Language Models: Principles,\n  Taxonomy, Challenges, and Open Questions",
        "authors": "Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, Ting Liu",
        "year": 2024,
        "abstract": "The emergence of large language models (LLMs) has marked a significant\nbreakthrough in natural language processing (NLP), fueling a paradigm shift in\ninformation acquisition. Nevertheless, LLMs are prone to hallucination,\ngenerating plausible yet nonfactual content. This phenomenon raises significant\nconcerns over the reliability of LLMs in real-world information retrieval (IR)\nsystems and has attracted intensive research to detect and mitigate such\nhallucinations. Given the open-ended general-purpose attributes inherent to\nLLMs, LLM hallucinations present distinct challenges that diverge from prior\ntask-specific models. This divergence highlights the urgency for a nuanced\nunderstanding and comprehensive overview of recent advances in LLM\nhallucinations. In this survey, we begin with an innovative taxonomy of\nhallucination in the era of LLM and then delve into the factors contributing to\nhallucinations. Subsequently, we present a thorough overview of hallucination\ndetection methods and benchmarks. Our discussion then transfers to\nrepresentative methodologies for mitigating LLM hallucinations. Additionally,\nwe delve into the current limitations faced by retrieval-augmented LLMs in\ncombating hallucinations, offering insights for developing more robust IR\nsystems. Finally, we highlight the promising research directions on LLM\nhallucinations, including hallucination in large vision-language models and\nunderstanding of knowledge boundaries in LLM hallucinations.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2311.05232v2",
        "arxiv": "2311.05232v2",
        "pdf": "http://arxiv.org/pdf/2311.05232v2",
        "citations": 700
    },
    {
        "id": "omnidocbench-benchmarking-diverse-pdf-document-parsing-with-comprehensive-annotations",
        "title": "OmniDocBench: Benchmarking Diverse PDF Document Parsing with  Comprehensive Annotations",
        "authors": "Linke Ouyang, Yuan Qu, Hongbin Zhou, Jiawei Zhu, Rui Zhang, Qunshu Lin, Bin Wang, Zhiyuan Zhao, Man Jiang, Xiaomeng Zhao, Jin Shi, Fan Wu, Pei Chu, Minghao Liu, Zhenxiang Li, Chao Xu, Bo Zhang, Botian Shi, Zhongying Tu, Conghui He",
        "year": 2024,
        "abstract": "Document content extraction is a critical task in computer vision,\nunderpinning the data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) systems. Despite recent progress, current\ndocument parsing methods have not been fairly and comprehensively evaluated due\nto the narrow coverage of document types and the simplified, unrealistic\nevaluation procedures in existing benchmarks. To address these gaps, we\nintroduce OmniDocBench, a novel benchmark featuring high-quality annotations\nacross nine document sources, including academic papers, textbooks, and more\nchallenging cases such as handwritten notes and densely typeset newspapers.\nOmniDocBench supports flexible, multi-level evaluations--ranging from an\nend-to-end assessment to the task-specific and attribute--based analysis using\n19 layout categories and 15 attribute labels. We conduct a thorough evaluation\nof both pipeline-based methods and end-to-end vision-language models, revealing\ntheir strengths and weaknesses across different document types. OmniDocBench\nsets a new standard for the fair, diverse, and fine-grained evaluation in\ndocument parsing. Dataset and code are available at\nhttps://github.com/opendatalab/OmniDocBench.",
        "category": "Parsing",
        "url": "https://arxiv.org/abs/2412.07626v2",
        "arxiv": "2412.07626v2",
        "pdf": "http://arxiv.org/pdf/2412.07626v2",
        "citations": 14
    },
    {
        "id": "tree-of-thoughts-deliberate-problem-solving-with-large-language-models",
        "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
        "authors": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan",
        "year": 2023,
        "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nhttps://github.com/princeton-nlp/tree-of-thought-llm.",
        "category": "Prompting",
        "url": "https://arxiv.org/abs/2305.10601v2",
        "arxiv": "2305.10601v2",
        "pdf": "http://arxiv.org/pdf/2305.10601v2",
        "citations": 4294
    },
    {
        "id": "retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks",
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
        "authors": "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela",
        "year": 2020,
        "abstract": "Large pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when fine-tuned on\ndownstream NLP tasks. However, their ability to access and precisely manipulate\nknowledge is still limited, and hence on knowledge-intensive tasks, their\nperformance lags behind task-specific architectures. Additionally, providing\nprovenance for their decisions and updating their world knowledge remain open\nresearch problems. Pre-trained models with a differentiable access mechanism to\nexplicit non-parametric memory can overcome this issue, but have so far been\nonly investigated for extractive downstream tasks. We explore a general-purpose\nfine-tuning recipe for retrieval-augmented generation (RAG) -- models which\ncombine pre-trained parametric and non-parametric memory for language\ngeneration. We introduce RAG models where the parametric memory is a\npre-trained seq2seq model and the non-parametric memory is a dense vector index\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\nformulations, one which conditions on the same retrieved passages across the\nwhole generated sequence, the other can use different passages per token. We\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\ntasks and set the state-of-the-art on three open domain QA tasks, outperforming\nparametric seq2seq models and task-specific retrieve-and-extract architectures.\nFor language generation tasks, we find that RAG models generate more specific,\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\nbaseline.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2005.11401v4",
        "arxiv": "2005.11401v4",
        "pdf": "http://arxiv.org/pdf/2005.11401v4",
        "citations": 12239
    },
    {
        "id": "graph-of-thoughts-solving-elaborate-problems-with-large-language-models",
        "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
        "authors": "Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler",
        "year": 2023,
        "abstract": "We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by >31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.",
        "category": "Prompting",
        "url": "https://arxiv.org/abs/2308.09687v4",
        "arxiv": "2308.09687v4",
        "pdf": "http://arxiv.org/pdf/2308.09687v4",
        "citations": 1325
    },
    {
        "id": "thread-of-thought-unraveling-chaotic-contexts",
        "title": "Thread of Thought Unraveling Chaotic Contexts",
        "authors": "Yucheng Zhou, Xiubo Geng, Tao Shen, Chongyang Tao, Guodong Long, Jian-Guang Lou, Jianbing Shen",
        "year": 2023,
        "abstract": "Large Language Models (LLMs) have ushered in a transformative era in the\nfield of natural language processing, excelling in tasks related to text\ncomprehension and generation. Nevertheless, they encounter difficulties when\nconfronted with chaotic contexts (e.g., distractors rather than long irrelevant\ncontext), leading to the inadvertent omission of certain details within the\nchaotic context. In response to these challenges, we introduce the \"Thread of\nThought\" (ThoT) strategy, which draws inspiration from human cognitive\nprocesses. ThoT systematically segments and analyzes extended contexts while\nadeptly selecting pertinent information. This strategy serves as a versatile\n\"plug-and-play\" module, seamlessly integrating with various LLMs and prompting\ntechniques. In the experiments, we utilize the PopQA and EntityQ datasets, as\nwell as a Multi-Turn Conversation Response dataset (MTCR) we collected, to\nillustrate that ThoT significantly improves reasoning performance compared to\nother prompting techniques.",
        "category": "Prompting",
        "url": "https://arxiv.org/abs/2311.08734v1",
        "arxiv": "2311.08734v1",
        "pdf": "http://arxiv.org/pdf/2311.08734v1",
        "citations": 87
    },
    {
        "id": "a-systematic-survey-of-prompt-engineering-in-large-language-models-techniques-and-applications",
        "title": "A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications",
        "authors": "Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, Aman Chadha",
        "year": 2024,
        "abstract": "Prompt engineering has emerged as an indispensable technique for extending\nthe capabilities of large language models (LLMs) and vision-language models\n(VLMs). This approach leverages task-specific instructions, known as prompts,\nto enhance model efficacy without modifying the core model parameters. Rather\nthan updating the model parameters, prompts allow seamless integration of\npre-trained models into downstream tasks by eliciting desired model behaviors\nsolely based on the given prompt. Prompts can be natural language instructions\nthat provide context to guide the model or learned vector representations that\nactivate relevant knowledge. This burgeoning field has enabled success across\nvarious applications, from question-answering to commonsense reasoning.\nHowever, there remains a lack of systematic organization and understanding of\nthe diverse prompt engineering methods and techniques. This survey paper\naddresses the gap by providing a structured overview of recent advancements in\nprompt engineering, categorized by application area. For each prompting\napproach, we provide a summary detailing the prompting methodology, its\napplications, the models involved, and the datasets utilized. We also delve\ninto the strengths and limitations of each approach and include a taxonomy\ndiagram and table summarizing datasets, models, and critical points of each\nprompting technique. This systematic analysis enables a better understanding of\nthis rapidly developing field and facilitates future research by illuminating\nopen challenges and opportunities for prompt engineering.",
        "category": "Prompting",
        "url": "https://arxiv.org/abs/2402.07927v2",
        "arxiv": "2402.07927v2",
        "pdf": "http://arxiv.org/pdf/2402.07927v2",
        "citations": 1050
    },
    {
        "id": "palm-scaling-language-modeling-with-pathways",
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "authors": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, Noah Fiedel",
        "year": 2022,
        "abstract": "Large language models have been shown to achieve remarkable performance\nacross a variety of natural language tasks using few-shot learning, which\ndrastically reduces the number of task-specific training examples needed to\nadapt the model to a particular application. To further our understanding of\nthe impact of scale on few-shot learning, we trained a 540-billion parameter,\ndensely activated, Transformer language model, which we call Pathways Language\nModel PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML\nsystem which enables highly efficient training across multiple TPU Pods. We\ndemonstrate continued benefits of scaling by achieving state-of-the-art\nfew-shot learning results on hundreds of language understanding and generation\nbenchmarks. On a number of these tasks, PaLM 540B achieves breakthrough\nperformance, outperforming the finetuned state-of-the-art on a suite of\nmulti-step reasoning tasks, and outperforming average human performance on the\nrecently released BIG-bench benchmark. A significant number of BIG-bench tasks\nshowed discontinuous improvements from model scale, meaning that performance\nsteeply increased as we scaled to our largest model. PaLM also has strong\ncapabilities in multilingual tasks and source code generation, which we\ndemonstrate on a wide array of benchmarks. We additionally provide a\ncomprehensive analysis on bias and toxicity, and study the extent of training\ndata memorization with respect to model scale. Finally, we discuss the ethical\nconsiderations related to large language models and discuss potential\nmitigation strategies.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2204.02311v5",
        "arxiv": "2204.02311v5",
        "pdf": "http://arxiv.org/pdf/2204.02311v5",
        "citations": 7624
    },
    {
        "id": "llama-open-and-efficient-foundation-language-models",
        "title": "LLaMA: Open and Efficient Foundation Language Models",
        "authors": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample",
        "year": 2023,
        "abstract": "We introduce LLaMA, a collection of foundation language models ranging from\n7B to 65B parameters. We train our models on trillions of tokens, and show that\nit is possible to train state-of-the-art models using publicly available\ndatasets exclusively, without resorting to proprietary and inaccessible\ndatasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,\nand LLaMA-65B is competitive with the best models, Chinchilla-70B and\nPaLM-540B. We release all our models to the research community.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2302.13971v1",
        "arxiv": "2302.13971v1",
        "pdf": "http://arxiv.org/pdf/2302.13971v1",
        "citations": 20564
    },
    {
        "id": "a-comprehensive-overview-and-comparative-analysis-on-deep-learning-models-cnn-rnn-lstm-gru",
        "title": "A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU",
        "authors": "Farhad Mortezapour Shiri, Thinagaran Perumal, Norwati Mustapha, Raihani Mohamed",
        "year": 2023,
        "abstract": "Deep learning (DL) has emerged as a powerful subset of machine learning (ML)\nand artificial intelligence (AI), outperforming traditional ML methods,\nespecially in handling unstructured and large datasets. Its impact spans across\nvarious domains, including speech recognition, healthcare, autonomous vehicles,\ncybersecurity, predictive analytics, and more. However, the complexity and\ndynamic nature of real-world problems present challenges in designing effective\ndeep learning models. Consequently, several deep learning models have been\ndeveloped to address different problems and applications. In this article, we\nconduct a comprehensive survey of various deep learning models, including\nConvolutional Neural Network (CNN), Recurrent Neural Network (RNN), Temporal\nConvolutional Networks (TCN), Transformer, Kolmogorov-Arnold networks (KAN),\nGenerative Models, Deep Reinforcement Learning (DRL), and Deep Transfer\nLearning. We examine the structure, applications, benefits, and limitations of\neach model. Furthermore, we perform an analysis using three publicly available\ndatasets: IMDB, ARAS, and Fruit-360. We compared the performance of six\nrenowned deep learning models: CNN, RNN, Long Short-Term Memory (LSTM),\nBidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU alongside\ntwo newer models, TCN and Transformer, using the IMDB and ARAS datasets.\nAdditionally, we evaluated the performance of eight CNN-based models, including\nVGG (Visual Geometry Group), Inception, ResNet (Residual Network),\nInceptionResNet, Xception (Extreme Inception), MobileNet, DenseNet (Dense\nConvolutional Network), and NASNet (Neural Architecture Search Network), for\nimage classification tasks using the Fruit-360 dataset.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2305.17473v4",
        "arxiv": "2305.17473v4",
        "pdf": "http://arxiv.org/pdf/2305.17473v4",
        "citations": 445
    },
    {
        "id": "class-based-n-gram-models-of-natural-language",
        "title": "Class-based n-gram models of natural language",
        "authors": "Brown, Peter F. and deSouza, Peter V. and Mercer, Robert L. and Pietra, Vincent J. Della and Lai, Jenifer C.",
        "year": 1994,
        "abstract": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics.",
        "category": "LLM",
        "url": "https://dl.acm.org/doi/10.5555/176313.176316",
        "pdf": "https://dl.acm.org/doi/pdf/10.5555/176313.176316",
        "citations": 4805
    },
    {
        "id": "on-the-theoretical-limitations-of-embedding-based-retrieval",
        "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
        "authors": "Orion Weller, Michael Boratko, Iftekhar Naim, Jinhyuk Lee",
        "year": 2025,
        "abstract": "Vector embeddings have been tasked with an ever-increasing set of retrieval\ntasks over the years, with a nascent rise in using them for reasoning,\ninstruction-following, coding, and more. These new benchmarks push embeddings\nto work for any query and any notion of relevance that could be given. While\nprior works have pointed out theoretical limitations of vector embeddings,\nthere is a common assumption that these difficulties are exclusively due to\nunrealistic queries, and those that are not can be overcome with better\ntraining data and larger models. In this work, we demonstrate that we may\nencounter these theoretical limitations in realistic settings with extremely\nsimple queries. We connect known results in learning theory, showing that the\nnumber of top-k subsets of documents capable of being returned as the result of\nsome query is limited by the dimension of the embedding. We empirically show\nthat this holds true even if we restrict to k=2, and directly optimize on the\ntest set with free parameterized embeddings. We then create a realistic dataset\ncalled LIMIT that stress tests models based on these theoretical results, and\nobserve that even state-of-the-art models fail on this dataset despite the\nsimple nature of the task. Our work shows the limits of embedding models under\nthe existing single vector paradigm and calls for future research to develop\nmethods that can resolve this fundamental limitation.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2508.21038v1",
        "arxiv": "2508.21038v1",
        "pdf": "http://arxiv.org/pdf/2508.21038v1",
        "citations": 15
    },
    {
        "id": "a-comprehensive-evaluation-of-quantization-strategies-for-large-language-models",
        "title": "A Comprehensive Evaluation of Quantization Strategies for Large Language Models",
        "authors": "Renren Jin, Jiangcun Du, Wuwei Huang, Wei Liu, Jian Luan, Bin Wang, Deyi Xiong",
        "year": 2024,
        "abstract": "Increasing the number of parameters in large language models (LLMs) usually\nimproves performance in downstream tasks but raises compute and memory costs,\nmaking deployment difficult in resource-limited settings. Quantization\ntechniques, which reduce the bits needed for model weights or activations with\nminimal performance loss, have become popular due to the rise of LLMs. However,\nmost quantization studies use pre-trained LLMs, and the impact of quantization\non instruction-tuned LLMs and the relationship between perplexity and benchmark\nperformance of quantized LLMs are not well understood. Evaluation of quantized\nLLMs is often limited to language modeling and a few classification tasks,\nleaving their performance on other benchmarks unclear. To address these gaps,\nwe propose a structured evaluation framework consisting of three critical\ndimensions: (1) knowledge \\& capacity, (2) alignment, and (3) efficiency, and\nconduct extensive experiments across ten diverse benchmarks. Our experimental\nresults indicate that LLMs with 4-bit quantization can retain performance\ncomparable to their non-quantized counterparts, and perplexity can serve as a\nproxy metric for quantized LLMs on most benchmarks. Furthermore, quantized LLMs\nwith larger parameter scales can outperform smaller LLMs. Despite the memory\nsavings achieved through quantization, it can also slow down the inference\nspeed of LLMs. Consequently, substantial engineering efforts and hardware\nsupport are imperative to achieve a balanced optimization of decoding speed and\nmemory consumption in the context of quantized LLMs.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2402.16775v2",
        "arxiv": "2402.16775v2",
        "pdf": "http://arxiv.org/pdf/2402.16775v2",
        "citations": 51
    },
    {
        "id": "large-language-models-a-survey",
        "title": "Large Language Models: A Survey",
        "authors": "Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao",
        "year": 2024,
        "abstract": "Large Language Models (LLMs) have drawn a lot of attention due to their\nstrong performance on a wide range of natural language tasks, since the release\nof ChatGPT in November 2022. LLMs' ability of general-purpose language\nunderstanding and generation is acquired by training billions of model's\nparameters on massive amounts of text data, as predicted by scaling laws\n\\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while\nvery recent, is evolving rapidly in many different ways. In this paper, we\nreview some of the most prominent LLMs, including three popular LLM families\n(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and\nlimitations. We also give an overview of techniques developed to build, and\naugment LLMs. We then survey popular datasets prepared for LLM training,\nfine-tuning, and evaluation, review widely used LLM evaluation metrics, and\ncompare the performance of several popular LLMs on a set of representative\nbenchmarks. Finally, we conclude the paper by discussing open challenges and\nfuture research directions.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2402.06196v3",
        "arxiv": "2402.06196v3",
        "pdf": "http://arxiv.org/pdf/2402.06196v3",
        "citations": 1432
    },
    {
        "id": "chain-of-thought-prompting-elicits-reasoning-in-large-language-models",
        "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
        "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou",
        "year": 2022,
        "abstract": "We explore how generating a chain of thought -- a series of intermediate\nreasoning steps -- significantly improves the ability of large language models\nto perform complex reasoning. In particular, we show how such reasoning\nabilities emerge naturally in sufficiently large language models via a simple\nmethod called chain of thought prompting, where a few chain of thought\ndemonstrations are provided as exemplars in prompting. Experiments on three\nlarge language models show that chain of thought prompting improves performance\non a range of arithmetic, commonsense, and symbolic reasoning tasks. The\nempirical gains can be striking. For instance, prompting a 540B-parameter\nlanguage model with just eight chain of thought exemplars achieves state of the\nart accuracy on the GSM8K benchmark of math word problems, surpassing even\nfinetuned GPT-3 with a verifier.",
        "category": "Prompting",
        "url": "https://arxiv.org/abs/2201.11903v6",
        "arxiv": "2201.11903v6",
        "pdf": "http://arxiv.org/pdf/2201.11903v6",
        "citations": 20506
    },
    {
        "id": "language-models-are-few-shot-learners",
        "title": "Language Models are Few-Shot Learners",
        "authors": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei",
        "year": 2020,
        "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and\nbenchmarks by pre-training on a large corpus of text followed by fine-tuning on\na specific task. While typically task-agnostic in architecture, this method\nstill requires task-specific fine-tuning datasets of thousands or tens of\nthousands of examples. By contrast, humans can generally perform a new language\ntask from only a few examples or from simple instructions - something which\ncurrent NLP systems still largely struggle to do. Here we show that scaling up\nlanguage models greatly improves task-agnostic, few-shot performance, sometimes\neven reaching competitiveness with prior state-of-the-art fine-tuning\napproaches. Specifically, we train GPT-3, an autoregressive language model with\n175 billion parameters, 10x more than any previous non-sparse language model,\nand test its performance in the few-shot setting. For all tasks, GPT-3 is\napplied without any gradient updates or fine-tuning, with tasks and few-shot\ndemonstrations specified purely via text interaction with the model. GPT-3\nachieves strong performance on many NLP datasets, including translation,\nquestion-answering, and cloze tasks, as well as several tasks that require\non-the-fly reasoning or domain adaptation, such as unscrambling words, using a\nnovel word in a sentence, or performing 3-digit arithmetic. At the same time,\nwe also identify some datasets where GPT-3's few-shot learning still struggles,\nas well as some datasets where GPT-3 faces methodological issues related to\ntraining on large web corpora. Finally, we find that GPT-3 can generate samples\nof news articles which human evaluators have difficulty distinguishing from\narticles written by humans. We discuss broader societal impacts of this finding\nand of GPT-3 in general.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/2005.14165v4",
        "arxiv": "2005.14165v4",
        "pdf": "http://arxiv.org/pdf/2005.14165v4",
        "citations": 56058
    },
    {
        "id": "bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language  Understanding",
        "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",
        "year": 2018,
        "abstract": "We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\nlanguage representation models, BERT is designed to pre-train deep\nbidirectional representations from unlabeled text by jointly conditioning on\nboth left and right context in all layers. As a result, the pre-trained BERT\nmodel can be fine-tuned with just one additional output layer to create\nstate-of-the-art models for a wide range of tasks, such as question answering\nand language inference, without substantial task-specific architecture\nmodifications.\n  BERT is conceptually simple and empirically powerful. It obtains new\nstate-of-the-art results on eleven natural language processing tasks, including\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).",
        "category": "LLM",
        "url": "https://arxiv.org/abs/1810.04805v2",
        "arxiv": "1810.04805v2",
        "pdf": "http://arxiv.org/pdf/1810.04805v2",
        "citations": 146523
    },
    {
        "id": "attention-is-all-you-need",
        "title": "Attention Is All You Need",
        "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
        "year": 2017,
        "abstract": "The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data.",
        "category": "LLM",
        "url": "https://arxiv.org/abs/1706.03762v7",
        "arxiv": "1706.03762v7",
        "pdf": "http://arxiv.org/pdf/1706.03762v7",
        "citations": 198836
    },
    {
        "id": "docling-an-efficient-open-source-toolkit-for-ai-driven-document-conversion",
        "title": "Docling: An Efficient Open-Source Toolkit for AI-driven Document  Conversion",
        "authors": "Nikolaos Livathinos, Christoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panos Vagenas, Cesar Berrospi Ramis, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar",
        "year": 2025,
        "abstract": "We introduce Docling, an easy-to-use, self-contained, MIT-licensed,\nopen-source toolkit for document conversion, that can parse several types of\npopular document formats into a unified, richly structured representation. It\nis powered by state-of-the-art specialized AI models for layout analysis\n(DocLayNet) and table structure recognition (TableFormer), and runs efficiently\non commodity hardware in a small resource budget. Docling is released as a\nPython package and can be used as a Python API or as a CLI tool. Docling's\nmodular architecture and efficient document representation make it easy to\nimplement extensions, new features, models, and customizations. Docling has\nbeen already integrated in other popular open-source frameworks (e.g.,\nLangChain, LlamaIndex, spaCy), making it a natural fit for the processing of\ndocuments and the development of high-end applications. The open-source\ncommunity has fully engaged in using, promoting, and developing for Docling,\nwhich gathered 10k stars on GitHub in less than a month and was reported as the\nNo. 1 trending repository in GitHub worldwide in November 2024.",
        "category": "Parsing",
        "url": "https://arxiv.org/abs/2501.17887v1",
        "arxiv": "2501.17887v1",
        "pdf": "http://arxiv.org/pdf/2501.17887v1",
        "citations": 16
    },
    {
        "id": "a-comparative-study-of-pdf-parsing-tools-across-diverse-document-categories",
        "title": "A Comparative Study of PDF Parsing Tools Across Diverse Document Categories",
        "authors": "Narayan S. Adhikari, Shradha Agarwal",
        "year": 2025,
        "abstract": "PDF is one of the most prominent data formats, making PDF parsing crucial for\ninformation extraction and retrieval, particularly with the rise of RAG\nsystems. While various PDF parsing tools exist, their effectiveness across\ndifferent document types remains understudied, especially beyond academic\npapers. Our research aims to address this gap by comparing 10 popular PDF\nparsing tools across 6 document categories using the DocLayNet dataset. These\ntools include PyPDF, pdfminer-six, PyMuPDF, pdfplumber, pypdfium2,\nUnstructured, Tabula, Camelot, as well as the deep learning-based tools Nougat\nand Table Transformer(TATR). We evaluated both text extraction and table\ndetection capabilities. For text extraction, PyMuPDF and pypdfium generally\noutperformed others, but all parsers struggled with Scientific and Patent\ndocuments. For these challenging categories, learning-based tools like Nougat\ndemonstrated superior performance. In table detection, TATR excelled in the\nFinancial, Patent, Law & Regulations, and Scientific categories. Table\ndetection tool Camelot performed best for tender documents, while PyMuPDF\nperformed superior in the Manual category. Our findings highlight the\nimportance of selecting appropriate parsing tools based on document type and\nspecific tasks, providing valuable insights for researchers and practitioners\nworking with diverse document sources.",
        "category": "Parsing",
        "url": "https://arxiv.org/abs/2410.09871v2",
        "arxiv": "2410.09871v2",
        "pdf": "http://arxiv.org/pdf/2410.09871v2",
        "citations": 19
    },
    {
        "id": "a-benchmark-of-pdf-information-extraction-tools-using-a-multi-task-and-multi-domain-evaluation-framework-for-academic-documents",
        "title": "A Benchmark of PDF Information Extraction Tools using a Multi-Task and Multi-Domain Evaluation Framework for Academic Documents",
        "authors": "Norman Meuschke, Apurva Jagdale, Timo Spinde, Jelena Mitrović, Bela Gipp",
        "year": 2025,
        "abstract": "Extracting information from academic PDF documents is crucial for numerous\nindexing, retrieval, and analysis use cases. Choosing the best tool to extract\nspecific content elements is difficult because many, technically diverse tools\nare available, but recent performance benchmarks are rare. Moreover, such\nbenchmarks typically cover only a few content elements like header metadata or\nbibliographic references and use smaller datasets from specific academic\ndisciplines. We provide a large and diverse evaluation framework that supports\nmore extraction tasks than most related datasets. Our framework builds upon\nDocBank, a multi-domain dataset of 1.5M annotated content elements extracted\nfrom 500K pages of research papers on arXiv. Using the new framework, we\nbenchmark ten freely available tools in extracting document metadata,\nbibliographic references, tables, and other content elements from academic PDF\ndocuments. GROBID achieves the best metadata and reference extraction results,\nfollowed by CERMINE and Science Parse. For table extraction, Adobe Extract\noutperforms other tools, even though the performance is much lower than for\nother content elements. All tools struggle to extract lists, footers, and\nequations. We conclude that more research on improving and combining tools is\nnecessary to achieve satisfactory extraction quality for most content elements.\nEvaluation datasets and frameworks like the one we present support this line of\nresearch. We make our data and code publicly available to contribute toward\nthis goal.",
        "category": "Parsing",
        "url": "https://arxiv.org/abs/2303.09957v1",
        "arxiv": "2303.09957v1",
        "pdf": "http://arxiv.org/pdf/2303.09957v1",
        "citations": 33
    },
    {
        "id": "retrieval-augmented-generation-for-large-language-models-a-survey",
        "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
        "authors": "Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang",
        "year": 2023,
        "abstract": "Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2312.10997",
        "arxiv": "2312.10997",
        "pdf": "https://arxiv.org/pdf/2312.10997.pdf",
        "citations": 3343
    },
    {
        "id": "retrieval-augmented-generation-for-ai-generated-content-a-survey",
        "title": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
        "authors": "Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui",
        "year": 2024,
        "abstract": "Advancements in model algorithms, the growth of foundational models, and access to high-quality datasets have propelled the evolution of Artificial Intelligence Generated Content (AIGC). Despite its notable successes, AIGC still faces hurdles such as updating knowledge, handling long-tail data, mitigating data leakage, and managing high training and inference costs. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores, leading to higher accuracy and better robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator, distilling the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2402.19473",
        "arxiv": "2402.19473",
        "pdf": "https://arxiv.org/pdf/2402.19473.pdf",
        "citations": 520
    },
    {
        "id": "query-rewriting-for-retrieval-augmented-large-language-models",
        "title": "Query Rewriting for Retrieval-Augmented Large Language Models",
        "authors": "Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan",
        "year": 2023,
        "abstract": "Large Language Models (LLMs) play powerful, black-box readers in the retrieve-then-read pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval. We first prompt an LLM to generate the query, then use a web search engine to retrieve contexts. Furthermore, to better align the query to the frozen modules, we propose a trainable scheme for our pipeline. A small language model is adopted as a trainable rewriter to cater to the black-box LLM reader. The rewriter is trained using the feedback of the LLM reader by reinforcement learning. Evaluation is conducted on downstream tasks, open-domain QA and multiple-choice QA. Experiments results show consistent performance improvement, indicating that our framework is proven effective and scalable, and brings a new framework for retrieval-augmented LLM.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2305.14283",
        "arxiv": "2305.14283",
        "pdf": "https://arxiv.org/pdf/2305.14283.pdf",
        "citations": 495
    },
    {
        "id": "precise-zero-shot-dense-retrieval-without-relevance-labels",
        "title": "Precise Zero-Shot Dense Retrieval without Relevance Labels",
        "authors": "Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan",
        "year": 2022,
        "abstract": "While dense retrieval has been shown effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance label is available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a query, HyDE first zero-shot instructs an instruction-following language model (e.g. InstructGPT) to generate a hypothetical document. The document captures relevance patterns but is unreal and may contain false details. Then, an unsupervised contrastively learned encoder~(e.g. Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, where similar real documents are retrieved based on vector similarity. This second step ground the generated document to the actual corpus, with the encoder's dense bottleneck filtering out the incorrect details. Our experiments show that HyDE significantly outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to fine-tuned retrievers, across various tasks (e.g. web search, QA, fact verification) and languages~(e.g. sw, ko, ja).",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2212.10496",
        "arxiv": "2212.10496",
        "pdf": "https://arxiv.org/pdf/2212.10496.pdf",
        "citations": 499
    },
    {
        "id": "searching-for-best-practices-in-retrieval-augmented-generation",
        "title": "Searching for Best Practices in Retrieval-Augmented Generation",
        "authors": "Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze Lv, Xiaoqing Zheng, Xuanjing Huang",
        "year": 2024,
        "abstract": "Retrieval-augmented generation (RAG) techniques have proven to be effective in integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains. While many RAG approaches have been proposed to enhance large language models through query-dependent retrievals, these approaches still suffer from their complex implementation and prolonged response times. Typically, a RAG workflow involves multiple processing steps, each of which can be executed in various ways. Here, we investigate existing RAG approaches and their potential combinations to identify optimal RAG practices. Through extensive experiments, we suggest several strategies for deploying RAG that balance both performance and efficiency. Moreover, we demonstrate that multimodal retrieval techniques can significantly enhance question-answering capabilities about visual inputs and accelerate the generation of multimodal content using a \"retrieval as generation\" strategy.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2407.01219",
        "arxiv": "2407.01219",
        "pdf": "https://arxiv.org/pdf/2407.01219.pdf",
        "citations": 168
    },
    {
        "id": "agentic-retrieval-augmented-generation-a-survey-on-agentic-rag",
        "title": "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG",
        "authors": "Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei",
        "year": 2025,
        "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management. Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications. This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG.",
        "category": "RAG (Retrieval Augmented Generation)",
        "url": "https://arxiv.org/abs/2501.09136",
        "arxiv": "2501.09136",
        "pdf": "https://arxiv.org/pdf/2501.09136.pdf",
        "citations": 111
    },
    {
        "id": "llm-based-intelligent-agents",
        "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
        "authors": "Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, Xiuqiang He",
        "year": 2024,
        "abstract": "Intelligent agents stand out as a potential path toward artificial general intelligence (AGI). Thus, researchers have dedicated significant effort to diverse implementations for them. Benefiting from recent progress in large language models (LLMs), LLM-based agents that use universal natural language as an interface exhibit robust generalization capabilities across various applications -- from serving as autonomous general-purpose task assistants to applications in coding, social, and economic domains, LLM-based agents offer extensive exploration opportunities. This paper surveys current research to provide an in-depth overview of LLM-based intelligent agents within single-agent and multi-agent systems. It covers their definitions, research frameworks, and foundational components such as their composition, cognitive and planning methods, tool utilization, and responses to environmental feedback. We also delve into the mechanisms of deploying LLM-based agents in multi-agent systems, including multi-role collaboration, message passing, and strategies to alleviate communication issues between agents. The discussions also shed light on popular datasets and application scenarios. We conclude by envisioning prospects for LLM-based agents, considering the evolving landscape of AI and natural language processing.",
        "category": "Agentic AI",
        "url": "https://arxiv.org/abs/2401.03428",
        "arxiv": "2401.03428",
        "pdf": "https://arxiv.org/pdf/2401.03428.pdf",
        "citations": 163
    },
    {
        "id": "rise-of-llm-agents",
        "title": "The Rise and Potential of Large Language Model Based Agents: A Survey",
        "authors": "Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, Tao Gui",
        "year": 2023,
        "abstract": "For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field.",
        "category": "Agentic AI",
        "url": "https://arxiv.org/abs/2309.07864",
        "arxiv": "2309.07864",
        "pdf": "https://arxiv.org/pdf/2309.07864.pdf",
        "citations": 1501
    },
    {
        "id": "llm-multi-agent-systems-survey",
        "title": "A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges",
        "authors": "Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, Yi Yang",
        "year": 2024,
        "journal": "Machine Intelligence Research",
        "abstract": "The pursuit of more intelligent and credible autonomous systems, akin to human society, has been a long-standing endeavor for humans. Leveraging the exceptional reasoning and planning capabilities of large language models (LLMs), LLM-based agents have been proposed and have achieved remarkable success across a wide array of tasks. Notably, LLM-based multi-agent systems (MAS) are considered a promising pathway towards realizing general artificial intelligence that is equivalent to or surpasses human-level intelligence. In this paper, we present a comprehensive survey of these studies, offering a systematic review of LLM-based MAS. Adhering to the workflow of LLM-based multi-agent systems, we synthesize a general structure encompassing five key components: profile, perception, self-action, mutual interaction, and evolution. This unified framework encapsulates much of the previous work in the field. Furthermore, we illuminate the extensive applications of LLM-based MAS in two principal areas: problem-solving and world simulation. Finally, we discuss in detail several contemporary challenges and provide insights into potential future directions in this domain.",
        "category": "Agentic AI",
        "url": "https://link.springer.com/article/10.1007/s44336-024-00009-2",
        "doi": "10.1007/s44336-024-00009-2",
        "citations": 199
    }
]