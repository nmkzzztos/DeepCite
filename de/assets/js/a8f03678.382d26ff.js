"use strict";(self.webpackChunkdeepcite=self.webpackChunkdeepcite||[]).push([[9064],{5212:(e,t,a)=>{a.r(t),a.d(t,{default:()=>m});var s=a(6540),i=a(5204);const r={container:"container_JKIK",header:"header_B7WA",headerFadeIn:"headerFadeIn_Tdpi",title:"title_jyvJ",subtitle:"subtitle_T6cv",categorySection:"categorySection_fz_r",categoryTitle:"categoryTitle_I0cS",categorySlideIn:"categorySlideIn_uvQe",projectsGrid:"projectsGrid_zf8F",projectCard:"projectCard_qilu",cardEntrance:"cardEntrance_qif7",projectContent:"projectContent_cyMr",projectMain:"projectMain_qBrj",projectLinks:"projectLinks_GAx8",link:"link_LeEy",toggleButton:"toggleButton_um0q",abstractSection:"abstractSection_Pp2J",slideInFade:"slideInFade_Xh4n",projectHeader:"projectHeader_Xhyo",projectTitle:"projectTitle_aFUU",projectLink:"projectLink_FYcS",projectMeta:"projectMeta__kQ_",authors:"authors_NNI7",year:"year_z9mS",starsCount:"starsCount_XHuw",license:"license_yLg4",abstract:"abstract_Oz_I",projectFooter:"projectFooter_vWC8"},o=JSON.parse('[{"id":"omnidocbench","title":"OmniDocBench","authors":"opendatalab","year":2024,"abstract":"[CVPR 2025] A Comprehensive Benchmark for Document Parsing and Evaluation","category":"Document Processing","github":"https://github.com/opendatalab/OmniDocBench","stars":944,"license":"Apache License 2.0"},{"id":"system-prompts-and-models-of-ai-tools","title":"System Prompts and Models of AI Tools","authors":"x1xhlol","year":2025,"abstract":"FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models","category":"Prompting","github":"https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools","stars":92101,"license":"GNU General Public License v3.0"},{"id":"deepseek-ocr","title":"DeepSeek-OCR (3B-MoE-A570M)","authors":"deepseek-ai","year":2025,"abstract":"DeepSeek-OCR is an initial investigation into the feasibility of compressing long context via optical 2D mapping.","category":"Document Processing","github":"https://github.com/deepseek-ai/DeepSeek-OCR","huggingface":"https://huggingface.co/deepseek-ai/DeepSeek-OCR","stars":1391,"license":"MIT License"},{"id":"milvus","title":"Milvus","authors":"milvus-io","year":2019,"abstract":"Milvus is a high-performance vector database built for scale.","category":"Vector Databases","github":"https://github.com/milvus-io/milvus","docs":"https://milvus.io/docs","stars":37967,"license":"Apache License 2.0","demo":"https://milvus.io"},{"id":"qdrant","title":"Qdrant","authors":"qdrant","year":2020,"abstract":"Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/","category":"Vector Databases","github":"https://github.com/qdrant/qdrant","docs":"https://qdrant.tech/documentation/","stars":26622,"license":"Apache License 2.0","demo":"https://qdrant.tech"},{"id":"faiss","title":"Faiss","authors":"facebookresearch","year":2017,"abstract":"A library for efficient similarity search and clustering of dense vectors.","category":"Vector Databases","github":"https://github.com/facebookresearch/faiss","docs":"https://faiss.ai/index.html","stars":37537,"license":"MIT License","demo":"https://faiss.ai"},{"id":"paddleocr","title":"PaddleOCR (0.9B)","authors":"PaddlePaddle","year":2025,"abstract":"Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.","category":"Document Processing","github":"https://github.com/PaddlePaddle/PaddleOCR","huggingface":"https://huggingface.co/PaddlePaddle/PaddleOCR-VL","stars":57671,"license":"Apache License 2.0","demo":"https://www.paddleocr.ai"},{"id":"mteb","title":"MTEB","authors":"embeddings-benchmark","year":2022,"abstract":"Massive Text Embedding Benchmark","category":"Embeddings","github":"https://github.com/embeddings-benchmark/mteb","huggingface":"https://huggingface.co/spaces/mteb/leaderboard","stars":2898,"license":"Apache License 2.0","demo":"https://embeddings-benchmark.github.io/mteb/"},{"id":"nvidia/omni-embed-nemotron-3b","title":"Omni-Embed Nemotron 3B","authors":"NVIDIA","year":2025,"abstract":"NV-QwenOmni-Embed-3B-v1 is a versatile multimodal embedding model capable of encoding content across multiple modalities, including text, image, audio, and video, either individually or in combination, and supports retrieval using queries that can also be multimodal. It is designed to serve as a foundational component in multi-modal Retrieval-Augmented Generation (RAG) systems.","category":"Embeddings","huggingface":"https://huggingface.co/nvidia/omni-embed-nemotron-3b","license":"Nvidia Open Model License"},{"id":"qwen3-embedding","title":"Qwen3-Embedding (0.6B, 4B, and 8B)","authors":"QwenLM","year":2025,"abstract":"The Qwen3 Embedding model series is the latest proprietary model of the Qwen family, specifically designed for text embedding and ranking tasks. Building upon the dense foundational models of the Qwen3 series, it provides a comprehensive range of text embeddings and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the exceptional multilingual capabilities, long-text understanding, and reasoning skills of its foundational model. The Qwen3 Embedding series represents significant advancements in multiple text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bitext mining.","category":"Embeddings","github":"https://github.com/QwenLM/Qwen3-Embedding","stars":1475,"license":"Apache License"},{"id":"llama-cloud-services","title":"Llama Parse","authors":"run-llama","year":2024,"abstract":"Llama Parse is a library for parsing documents into a structured format.","category":"Document Processing","github":"https://github.com/run-llama/llama_cloud_services","stars":4178,"license":"MIT License","demo":"https://www.llamaindex.ai/llamaparse"},{"id":"lmstudio","title":"LMStudio","year":2024,"abstract":"LMStudio is a local LLM studio for running and managing LLMs.","category":"Local LLMs","docs":"https://lmstudio.ai/docs/app","demo":"https://lmstudio.ai/"},{"id":"llamacpp","title":"Llama.cpp","authors":"ggml-org","year":2023,"abstract":"LLM inference in C/C++","category":"Local LLMs","github":"https://github.com/ggml-org/llama.cpp","stars":87629,"license":"MIT License","docs":"https://llama-cpp-python.readthedocs.io/en/latest/"},{"id":"grobid","title":"Grobid","authors":"kermitt2","year":2012,"abstract":"A machine learning software for extracting information from scholarly documents","category":"Document Processing","github":"https://github.com/kermitt2/grobid","stars":4359,"license":"Apache License 2.0","docs":"https://grobid.readthedocs.io"},{"id":"transformers","title":"Transformers","authors":"huggingface","year":2018,"abstract":"\ud83e\udd17 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ","category":"NLP Libraries","github":"https://github.com/huggingface/transformers","stars":150999,"license":"Apache License 2.0","demo":"https://huggingface.co/transformers"},{"id":"langchain","title":"LangChain","authors":"Harrison Chase, Ankush Gola, Chris Hager, Eliott Gunn, LangChain AI","year":2023,"abstract":"LangChain is a framework for developing applications powered by language models. It enables applications that are: Data-aware: connect a language model to other sources of data, Agentic: allow a language model to interact with its environment. LangChain provides standard, extendable interfaces and integrations for various components useful for working with LLMs.","category":"AI Frameworks","github":"https://github.com/langchain-ai/langchain","docs":"https://python.langchain.com/docs/get_started/introduction","demo":"https://chat.langchain.com/","stars":117119,"license":"MIT"},{"id":"llamaindex","title":"LlamaIndex","authors":"Jerry Liu, LlamaCloud","year":2023,"abstract":"LlamaIndex is a data framework for LLM applications to ingest, structure, and access private or domain-specific data. It provides tools for building search and retrieval systems, chatbots, and autonomous agents. The framework supports multiple data sources and offers advanced indexing strategies for efficient retrieval-augmented generation.","category":"AI Frameworks","github":"https://github.com/run-llama/llama_index","docs":"https://docs.llamaindex.ai/","stars":44701,"license":"MIT"},{"id":"chromadb","title":"ChromaDB","authors":"Chroma","year":2023,"abstract":"ChromaDB is the open-source embedding database. It is designed to make it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs. ChromaDB is fully open-source, and includes everything needed to build and deploy AI-powered applications.","category":"Vector Databases","github":"https://github.com/chroma-core/chroma","docs":"https://docs.trychroma.com/","demo":"https://www.trychroma.com/","stars":23836,"license":"Apache-2.0"},{"id":"weaviate","title":"Weaviate","authors":"Weaviate B.V.","year":2020,"abstract":"Weaviate is an open-source vector database that allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects. Weaviate is a low-latency vector search engine with support for different media types (text, images, etc.).","category":"Vector Databases","github":"https://github.com/weaviate/weaviate","demo":"https://weaviate.io/","docs":"https://docs.weaviate.io/weaviate","stars":14764,"license":"BSD-3-Clause"},{"id":"docling","title":"Docling","authors":"IBM Research, Christoph Auer, Nikolaos Livathinos","year":2024,"abstract":"Docling is an easy-to-use, self-contained, open-source toolkit for document conversion. It parses several types of popular document formats into a unified, richly structured representation. Powered by state-of-the-art AI models for layout analysis and table structure recognition, it runs efficiently on commodity hardware.","category":"Document Processing","github":"https://github.com/docling-project/docling","docs":"https://docling-project.github.io/docling/","stars":41400,"license":"MIT"},{"id":"unstructured","title":"Unstructured","authors":"Unstructured Technologies","year":2023,"abstract":"Unstructured is an open-source library for preprocessing, partitioning, and cleaning documents for use with LLM applications. It supports many file types and has integrations with major vector databases and LLM providers. The library can extract text, images, and metadata from complex document formats.","category":"Document Processing","github":"https://github.com/Unstructured-IO/unstructured","docs":"https://unstructured-io.github.io/unstructured/","stars":12916,"license":"Apache-2.0"},{"id":"langgraph","title":"LangGraph","authors":"LangChain AI","year":2024,"abstract":"LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It supports branching, looping, and persistence of state.","category":"Agent Frameworks","github":"https://github.com/langchain-ai/langgraph","docs":"https://langchain-ai.github.io/langgraph/","stars":19691,"license":"MIT"},{"id":"sentence-transformers","title":"Sentence Transformers","authors":"Nils Reimers, UKP Lab","year":2019,"abstract":"Sentence Transformers is a Python framework for state-of-the-art sentence, text and image embeddings. It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like semantic search, semantic textual similarity, paraphrase mining, and more.","category":"Embeddings","github":"https://github.com/UKPLab/sentence-transformers","docs":"https://www.sbert.net/","stars":17675,"license":"Apache-2.0"},{"id":"ollama","title":"Ollama","authors":"Ollama Team","year":2023,"abstract":"Ollama is a user-friendly tool for running large language models locally. It allows you to run, create, and share large language models (LLMs) on your local machine. With Ollama, you can easily set up and run models like Llama 2, Mistral, and more without needing extensive technical knowledge.","category":"Local LLMs","github":"https://github.com/ollama/ollama","docs":"https://github.com/ollama/ollama","stars":153987,"license":"MIT"},{"id":"google/embeddinggemma-300m","title":"EmbeddingGemma (300M)","authors":"Google","year":2025,"abstract":"EmbeddingGemma is a 300M parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models. EmbeddingGemma produces vector representations of text, making it well-suited for search and retrieval tasks, including classification, clustering, and semantic similarity search. This model was trained with data in 100+ spoken languages.","category":"Embeddings","huggingface":"https://huggingface.co/google/embeddinggemma-300m","license":"License gemma"}]');var n=a(4848);const c=o.sort(((e,t)=>t.year-e.year)),l=[...new Set(c.map((e=>e.category)))];function d({project:e}){const[t,a]=(0,s.useState)(!1);return(0,n.jsxs)("div",{className:r.projectCard,children:[(0,n.jsxs)("div",{className:r.projectContent,children:[(0,n.jsxs)("div",{className:r.projectMain,children:[(0,n.jsx)("h3",{className:r.projectTitle,children:e.github||e.huggingface?(0,n.jsx)("a",{href:e.github||e.huggingface,target:"_blank",rel:"noopener noreferrer",className:r.projectLink,children:e.title}):e.title}),(0,n.jsx)("div",{className:r.projectMeta,children:(0,n.jsxs)("div",{className:r.projectMetaFooter,children:[(0,n.jsxs)("span",{className:r.year,children:["(",e.year,") "]}),e.license&&(0,n.jsx)("span",{className:r.license,children:e.license}),e.stars&&(0,n.jsxs)("span",{className:r.starsCount,children:["\u2b50 ",e.stars.toLocaleString()," stars"]})]})})]}),(0,n.jsxs)("div",{className:r.projectLinks,children:[e.github&&(0,n.jsx)("a",{href:e.github,target:"_blank",rel:"noopener noreferrer",className:r.link,children:"GitHub"}),e.huggingface&&(0,n.jsx)("a",{href:e.huggingface,target:"_blank",rel:"noopener noreferrer",className:r.link,children:"Hugging Face"}),e.docs&&(0,n.jsx)("a",{href:e.docs,target:"_blank",rel:"noopener noreferrer",className:r.link,children:"Docs"}),e.demo&&(0,n.jsx)("a",{href:e.demo,target:"_blank",rel:"noopener noreferrer",className:r.link,children:"Demo"}),(0,n.jsx)("button",{onClick:()=>{a(!t)},className:r.toggleButton,children:t?"Hide description":"Show description"})]})]}),t&&(0,n.jsx)("div",{className:r.abstractSection,children:(0,n.jsx)("p",{className:r.abstract,children:e.abstract})})]})}function g({category:e,projects:t}){return(0,n.jsxs)("section",{className:r.categorySection,children:[(0,n.jsx)("h2",{className:r.categoryTitle,children:e}),(0,n.jsx)("div",{className:r.projectsGrid,children:t.map((e=>(0,n.jsx)(d,{project:e},e.id)))})]})}function m(){return(0,n.jsx)(i.A,{title:"Projects - DeepCite",description:"Curated collection of influential AI/ML projects and tools for RAG, NLP, and agent development",children:(0,n.jsxs)("div",{className:r.container,children:[(0,n.jsxs)("header",{className:r.header,children:[(0,n.jsx)("h1",{className:r.title,children:"Projects"}),(0,n.jsx)("p",{className:r.subtitle,children:"Curated collection of influential AI/ML projects and tools"})]}),(0,n.jsx)("main",{className:r.main,children:l.map((e=>(0,n.jsx)(g,{category:e,projects:c.filter((t=>t.category===e))},e)))})]})})}}}]);